{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1d8efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Our modules\n",
    "from src.fx_data_loader import (\n",
    "    FXDataLoader, \n",
    "    FXDataMetadata, \n",
    "    FXDataIntegrityError,\n",
    "    create_sample_fx_data\n",
    ")\n",
    "\n",
    "# Show all warnings\n",
    "warnings.filterwarnings('always')\n",
    "\n",
    "print(\"‚úÖ Imports successful\")\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0660aa1",
   "metadata": {},
   "source": [
    "## 1. Generate Sample Data (For Testing Only)\n",
    "\n",
    "‚ö†Ô∏è **THIS IS SYNTHETIC DATA** - Replace with real data for actual analysis.\n",
    "\n",
    "For real data, download from:\n",
    "- **HistData.com** (free, bid prices, 1-min bars)\n",
    "- **Dukascopy** (tick data, requires processing)\n",
    "- **TrueFX** (free tick data, requires registration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad96fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data for testing the pipeline\n",
    "# DELETE THIS CELL when using real data\n",
    "\n",
    "pairs = [\"EURUSD\", \"GBPUSD\", \"USDJPY\"]\n",
    "data_dir = project_root / \"data\" / \"raw\" / \"fx\"\n",
    "\n",
    "for pair in pairs:\n",
    "    filepath = data_dir / f\"{pair}.csv\"\n",
    "    if not filepath.exists():\n",
    "        create_sample_fx_data(\n",
    "            pair=pair,\n",
    "            output_dir=str(data_dir),\n",
    "            days=30,\n",
    "            bar_interval_minutes=1\n",
    "        )\n",
    "    else:\n",
    "        print(f\"{pair}.csv already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2b3d1a",
   "metadata": {},
   "source": [
    "## 2. Load and Verify Data Integrity\n",
    "\n",
    "The loader will:\n",
    "1. Check for required columns\n",
    "2. Enforce UTC timezone\n",
    "3. Detect gaps, duplicates, extreme moves\n",
    "4. Surface all data quality issues\n",
    "\n",
    "**If integrity checks fail ‚Üí STOP. Do not proceed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc28d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize loader with explicit metadata\n",
    "# CHANGE THIS when using real data from different source\n",
    "\n",
    "metadata = FXDataMetadata(\n",
    "    source=\"Synthetic (for testing only)\",\n",
    "    broker=None,  # Not broker-specific\n",
    "    price_type=\"bid\",  # Assuming bid prices\n",
    "    timezone=\"UTC\",\n",
    "    volume_type=\"tick\",  # Tick volume, NOT real volume\n",
    "    spread_available=False,  # No bid/ask spread data\n",
    "    bar_interval=\"1min\",\n",
    "    dst_handling=\"utc_native\",  # UTC doesn't have DST\n",
    ")\n",
    "\n",
    "loader = FXDataLoader(\n",
    "    data_dir=str(data_dir),\n",
    "    metadata=metadata\n",
    ")\n",
    "\n",
    "print(\"Loader initialized with metadata:\")\n",
    "print(f\"  Source: {metadata.source}\")\n",
    "print(f\"  Price Type: {metadata.price_type}\")\n",
    "print(f\"  Timezone: {metadata.timezone}\")\n",
    "print(f\"  Volume: {metadata.volume_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f39e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load each pair and run integrity checks\n",
    "fx_data = {}\n",
    "\n",
    "for pair in pairs:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Loading {pair}...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        df = loader.load_csv(pair, verify=True, fail_on_warning=False)\n",
    "        fx_data[pair] = df\n",
    "        print(f\"‚úÖ Loaded {len(df):,} bars\")\n",
    "    except FXDataIntegrityError as e:\n",
    "        print(f\"‚ùå INTEGRITY FAILURE: {e}\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå FILE NOT FOUND: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b756e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print detailed integrity reports\n",
    "for pair in fx_data.keys():\n",
    "    loader.print_integrity_report(pair)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8028b61d",
   "metadata": {},
   "source": [
    "## 3. Visual Inspection\n",
    "\n",
    "Charts for:\n",
    "- Price overview (spot obvious issues)\n",
    "- Gap analysis\n",
    "- Session distribution\n",
    "- Return distribution (fat tails?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739c742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fx_overview(df: pd.DataFrame, pair: str):\n",
    "    \"\"\"Plot FX data overview for visual inspection.\"\"\"\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(14, 10))\n",
    "    fig.suptitle(f\"{pair} Data Overview - Visual Inspection\", fontsize=14)\n",
    "    \n",
    "    # 1. Price chart\n",
    "    ax = axes[0, 0]\n",
    "    ax.plot(df.index, df['close'], linewidth=0.5, alpha=0.8)\n",
    "    ax.set_title('Close Price')\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Price')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Returns distribution\n",
    "    ax = axes[0, 1]\n",
    "    returns = df['close'].pct_change().dropna()\n",
    "    ax.hist(returns, bins=100, density=True, alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(x=0, color='red', linestyle='--', alpha=0.5)\n",
    "    ax.set_title(f'Returns Distribution (std={returns.std()*100:.3f}%)')\n",
    "    ax.set_xlabel('Return')\n",
    "    ax.set_ylabel('Density')\n",
    "    \n",
    "    # 3. Time gaps histogram\n",
    "    ax = axes[1, 0]\n",
    "    diffs = df.index.to_series().diff().dropna()\n",
    "    diffs_minutes = diffs.dt.total_seconds() / 60\n",
    "    # Filter to show gaps up to 60 minutes\n",
    "    diffs_filtered = diffs_minutes[diffs_minutes <= 60]\n",
    "    ax.hist(diffs_filtered, bins=50, edgecolor='black', alpha=0.7)\n",
    "    ax.axvline(x=1, color='red', linestyle='--', label='Expected (1 min)')\n",
    "    ax.set_title('Time Gap Distribution (‚â§60 min)')\n",
    "    ax.set_xlabel('Gap (minutes)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.legend()\n",
    "    \n",
    "    # 4. Session distribution\n",
    "    ax = axes[1, 1]\n",
    "    session_counts = df['primary_session'].value_counts()\n",
    "    colors = {'london': 'blue', 'new_york': 'green', 'tokyo': 'red', \n",
    "              'sydney': 'orange', 'off_hours': 'gray'}\n",
    "    bar_colors = [colors.get(s, 'gray') for s in session_counts.index]\n",
    "    session_counts.plot(kind='bar', ax=ax, color=bar_colors, edgecolor='black')\n",
    "    ax.set_title('Bars by Session')\n",
    "    ax.set_xlabel('Session')\n",
    "    ax.set_ylabel('Bar Count')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 5. Volume by hour (if available)\n",
    "    ax = axes[2, 0]\n",
    "    if 'volume' in df.columns:\n",
    "        hourly_vol = df.groupby(df.index.hour)['volume'].mean()\n",
    "        hourly_vol.plot(kind='bar', ax=ax, color='steelblue', edgecolor='black')\n",
    "        ax.set_title('Average Tick Volume by Hour (UTC)')\n",
    "        ax.set_xlabel('Hour (UTC)')\n",
    "        ax.set_ylabel('Avg Tick Volume')\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, 'No volume data', ha='center', va='center', fontsize=12)\n",
    "        ax.set_title('Volume: N/A')\n",
    "    \n",
    "    # 6. Candle range distribution\n",
    "    ax = axes[2, 1]\n",
    "    ranges = df['high'] - df['low']\n",
    "    if 'JPY' in pair:\n",
    "        ranges_pips = ranges * 100\n",
    "    else:\n",
    "        ranges_pips = ranges * 10000\n",
    "    ax.hist(ranges_pips, bins=50, edgecolor='black', alpha=0.7)\n",
    "    ax.axvline(x=ranges_pips.median(), color='red', linestyle='--', \n",
    "               label=f'Median: {ranges_pips.median():.1f} pips')\n",
    "    ax.set_title('Candle Range Distribution')\n",
    "    ax.set_xlabel('Range (pips)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a16e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot overview for each pair\n",
    "for pair, df in fx_data.items():\n",
    "    plot_fx_overview(df, pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3615cab7",
   "metadata": {},
   "source": [
    "## 4. Gap Analysis\n",
    "\n",
    "Identify and categorize all gaps:\n",
    "- **Weekend gaps**: Expected (Fri 21:00 - Sun 21:00 UTC)\n",
    "- **Session gaps**: Lower liquidity periods\n",
    "- **Suspicious gaps**: Possible missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6517745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_gaps(df: pd.DataFrame, pair: str, expected_bar_minutes: int = 1):\n",
    "    \"\"\"Analyze and categorize time gaps in FX data.\"\"\"\n",
    "    \n",
    "    diffs = df.index.to_series().diff()\n",
    "    expected = pd.Timedelta(minutes=expected_bar_minutes)\n",
    "    \n",
    "    # Categorize gaps\n",
    "    gaps = pd.DataFrame({\n",
    "        'gap': diffs,\n",
    "        'gap_minutes': diffs.dt.total_seconds() / 60\n",
    "    }).dropna()\n",
    "    \n",
    "    # Weekend gaps (>24 hours)\n",
    "    weekend_gaps = gaps[gaps['gap'] > pd.Timedelta(hours=24)]\n",
    "    \n",
    "    # Suspicious gaps (5 min - 24 hours)\n",
    "    suspicious_gaps = gaps[\n",
    "        (gaps['gap'] > expected * 5) & \n",
    "        (gaps['gap'] <= pd.Timedelta(hours=24))\n",
    "    ]\n",
    "    \n",
    "    # Minor gaps (2-5x expected)\n",
    "    minor_gaps = gaps[\n",
    "        (gaps['gap'] > expected * 2) & \n",
    "        (gaps['gap'] <= expected * 5)\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nüìä GAP ANALYSIS: {pair}\")\n",
    "    print(f\"=\"*50)\n",
    "    print(f\"Total bars: {len(df):,}\")\n",
    "    print(f\"Expected gap: {expected_bar_minutes} minute(s)\")\n",
    "    print(f\"\\nGap Categories:\")\n",
    "    print(f\"  Weekend gaps (>24h): {len(weekend_gaps)}\")\n",
    "    print(f\"  Suspicious gaps (5min-24h): {len(suspicious_gaps)}\")\n",
    "    print(f\"  Minor gaps (2-5x): {len(minor_gaps)}\")\n",
    "    print(f\"  Normal gaps: {len(gaps) - len(weekend_gaps) - len(suspicious_gaps) - len(minor_gaps)}\")\n",
    "    \n",
    "    if len(suspicious_gaps) > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è SUSPICIOUS GAPS (investigate these):\")\n",
    "        for idx, row in suspicious_gaps.head(10).iterrows():\n",
    "            print(f\"  {idx}: {row['gap_minutes']:.0f} minutes\")\n",
    "    \n",
    "    return {\n",
    "        'weekend': weekend_gaps,\n",
    "        'suspicious': suspicious_gaps,\n",
    "        'minor': minor_gaps\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d2312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze gaps for each pair\n",
    "gap_analysis = {}\n",
    "for pair, df in fx_data.items():\n",
    "    gap_analysis[pair] = analyze_gaps(df, pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e00ed7",
   "metadata": {},
   "source": [
    "## 5. Data Summary Export\n",
    "\n",
    "Save integrity reports and summaries for documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3857786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save integrity reports\n",
    "results_dir = project_root / \"results\" / \"metrics\"\n",
    "\n",
    "for pair in fx_data.keys():\n",
    "    loader.save_integrity_report(pair, output_dir=str(results_dir))\n",
    "    \n",
    "    # Also get and print summary\n",
    "    summary = loader.get_data_summary(fx_data[pair], pair)\n",
    "    print(f\"\\n{pair} Summary:\")\n",
    "    print(f\"  Total bars: {summary['total_bars']:,}\")\n",
    "    print(f\"  Trading days: {summary['date_range']['trading_days']}\")\n",
    "    print(f\"  London bars: {summary['sessions']['london_bars']:,}\")\n",
    "    print(f\"  NY bars: {summary['sessions']['new_york_bars']:,}\")\n",
    "    print(f\"  Overlap bars: {summary['sessions']['overlap_bars']:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a004f224",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ùì MANDATORY VERIFICATION QUESTIONS\n",
    "\n",
    "**You MUST answer these before proceeding to any analysis.**\n",
    "\n",
    "### 1. What is the data source and broker?\n",
    "- **Source**: [Fill in - e.g., HistData.com, Dukascopy, OANDA export]\n",
    "- **Broker**: [Fill in - if broker-specific data]\n",
    "\n",
    "### 2. Is this bid, ask, or mid?\n",
    "- **Answer**: [Fill in]\n",
    "- **Implication**: [e.g., \"Bid prices - buys need ask estimate\"]\n",
    "\n",
    "### 3. What timezone is the data in?\n",
    "- **Answer**: [Should be UTC]\n",
    "- **Verified by**: [How did you verify?]\n",
    "\n",
    "### 4. How is DST handled?\n",
    "- **Answer**: [UTC-native / Local-shifted / Unknown]\n",
    "\n",
    "### 5. Is volume real or tick volume?\n",
    "- **Answer**: [Tick / Real / None]\n",
    "- **Implication**: [What does this mean for your analysis?]\n",
    "\n",
    "### 6. Are spreads available?\n",
    "- **Answer**: [Yes / No]\n",
    "- **If No**: [How will you model spreads later?]\n",
    "\n",
    "### 7. What FX-specific biases exist?\n",
    "- **Rollover**: [Acknowledged / Not applicable]\n",
    "- **Session gaps**: [Acknowledged / Not applicable]\n",
    "- **Broker filtering**: [Acknowledged / Not applicable]\n",
    "\n",
    "### 8. Data integrity verdict\n",
    "- **PASS / FAIL**: [Based on integrity checks]\n",
    "- **Proceed to Stage 3?**: [Yes / No]\n",
    "\n",
    "---\n",
    "\n",
    "‚ö†Ô∏è **If any answer is vague ‚Üí REDO STAGE 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa15345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final execution realism warning\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXECUTION REALISM WARNING\")\n",
    "print(\"=\"*60)\n",
    "print(loader.metadata.get_execution_realism_warning())\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"If you cannot explain exactly how this FX data lies to you,\")\n",
    "print(\"you are NOT ALLOWED to model it.\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
